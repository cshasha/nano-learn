{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import math\n",
    "from pylab import *\n",
    "import urllib\n",
    "import os\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from __future__ import division\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lmfit import Model\n",
    "import pickle\n",
    "pl.style.use('seaborn')\n",
    "pl.rc('font',family='Arial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = 300.\n",
    "Ms = 420000.\n",
    "kb = 1.381e-23 \n",
    "tau0 = 1e-10\n",
    "mu0 = 4*np.pi*1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visc_calc(T, mass_fraction):\n",
    "    glycerolDen = (1273.3-0.6121*T)/1000 \t\t\t#Density of Glycerol (g/cm3)\n",
    "    waterDen = (1-math.pow(((abs(T-4))/622),1.7)) \t#Density of water (g/cm3)\n",
    "    \n",
    "    ##Andreas Volk polynomial method\n",
    "    contraction_av = 1-math.pow(3.520E-8*((mass_fraction*100)),3)+math.pow(1.027E-6*((mass_fraction*100)),2)+2.5E-4*(mass_fraction*100)-1.691E-4\n",
    "    contraction = 1+contraction_av/100\n",
    "    \n",
    "    glycerolVisc=0.001*12100*np.exp((-1233+T)*T/(9900+70*T))\n",
    "    waterVisc=0.001*1.790*np.exp((-1230-T)*T/(36100+360*T))\n",
    "    \n",
    "    a=0.705-0.0017*T\n",
    "    b=(4.9+0.036*T)*np.power(a,2.5)\n",
    "    alpha=1-mass_fraction+(a*b*mass_fraction*(1-mass_fraction))/(a*mass_fraction+b*(1-mass_fraction))\n",
    "    A=np.log(waterVisc/glycerolVisc)\n",
    "    \n",
    "    viscosity_mix=glycerolVisc*np.exp(A*alpha)\n",
    "    \n",
    "    return viscosity_mix\n",
    "\n",
    "def power(my_list, p):\n",
    "    return [ x**p for x in my_list ]\n",
    "\n",
    "def calc_neel(size, k):\n",
    "    neel = []\n",
    "    for x in range(len(size)):\n",
    "        neel.append(tau0*np.exp(k[x]*4*np.pi*(1e-9*float(size[x]))**3*(24*kb*temp)**(-1)))\n",
    "    return neel\n",
    "\n",
    "def calc_brown(eta, hsize):\n",
    "    brown = []\n",
    "    for x in range(len(eta)):\n",
    "        brown.append(eta[x]*np.pi*(hsize[x]*1e-9)**3*(2*kb*temp)**(-1))\n",
    "    return brown\n",
    "\n",
    "def vol(my_list):\n",
    "    return[ np.pi*(1e-9*x)**3/6. for x in my_list ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freqs = []\n",
    "fields = []\n",
    "size = []\n",
    "third = []\n",
    "fifth = []\n",
    "hsize = []\n",
    "sigma = []\n",
    "eta = []\n",
    "b = []\n",
    "K = []\n",
    "phase1 = []\n",
    "phase3 = []\n",
    "gyro = []\n",
    "\n",
    "for f in os.listdir('fits'):\n",
    "    if f[-1] == 'v':\n",
    "        filename = 'fits/' + f\n",
    "        filedata = np.genfromtxt(filename, delimiter=',')\n",
    "        f = f[:-4]\n",
    "        s = str.split(f,\"_\")\n",
    "        size.append(float(s[0][:-2]))\n",
    "        fields.append(float(s[1][:-2]))\n",
    "        freqs.append(int(s[2][:-3])*1000)\n",
    "        sigma.append(0.1)\n",
    "        eta.append(8.9e-4)\n",
    "        moment = filedata[:,1]\n",
    "        third.append(abs(np.fft.fft(moment)[3]))\n",
    "        fifth.append(abs(np.fft.fft(moment)[5]))\n",
    "        phase1.append(np.angle(np.fft.fft(moment)[1]))\n",
    "        phase3.append(np.angle(np.fft.fft(moment)[3]))\n",
    "        if s[-1] == \"frozen\":\n",
    "            b.append(\"off\")\n",
    "        else:\n",
    "            b.append(\"on\")     \n",
    "        g = 1.\n",
    "        h = 50.\n",
    "        k = 5000.\n",
    "        for ss in range(2,len(s)):\n",
    "            if s[ss][0] == \"g\":\n",
    "                g = float(s[ss][1:])\n",
    "            if s[ss][0] == \"K\":\n",
    "                k = 1000*float(s[ss][1:])\n",
    "                if k > 25000:\n",
    "                    k /= 1000.\n",
    "            if s[ss][0] == \"H\":\n",
    "                h = float(s[ss][1:])\n",
    "        K.append(k)\n",
    "        hsize.append(h)\n",
    "        gyro.append(g)\n",
    "            \n",
    "sdata = pd.DataFrame({'frequency': freqs, 'field': fields,'size': size, 'sigma': sigma, \\\n",
    "                     'third': third, 'fifth': fifth, 'hsize': hsize, 'eta': eta, 'b': b, \\\n",
    "                     'K': K, 'phase1': phase1, 'phase3': phase3, 'gyro': gyro})\n",
    "\n",
    "sdata['5:3'] = sdata['fifth']/sdata['third']\n",
    "sdata['angF'] = 2*np.pi*sdata['frequency']\n",
    "sdata['Vc'] = vol(sdata['size'])\n",
    "sdata['Ms'] = 393023 * (1 - np.exp(-2.78258e8 * sdata['size']*1e-9))**57.87571 \n",
    "sdata['tauB'] = calc_brown(sdata['eta'],sdata['hsize'])\n",
    "sdata['tauN'] = calc_neel(sdata['size'], sdata['K'])\n",
    "sdata['tan1'] = abs(np.tan(sdata['phase1']))\n",
    "sdata['tan3'] = abs(np.tan(sdata['phase3']))\n",
    "sdata['tau'] = sdata['tan1']/sdata['angF']\n",
    "\n",
    "for index, row in sdata.iterrows():\n",
    "    T = row['frequency']**(-1)\n",
    "    t = np.arange(0,T,T/1000.)\n",
    "    H = 0.001*row['field']*np.cos(row['angF']*t)\n",
    "    V = (4/3)*np.pi*(row['size']*1e-9/2)**3\n",
    "    xi = row['Ms']*V*H/(kb*temp)\n",
    "    L = np.cosh(xi)/np.sinh(xi) - 1/xi\n",
    "    sdata.loc[index,'L5:3'] = abs(np.fft.fft(L)[5])/abs(np.fft.fft(L)[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brownian rotation off (frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999848354684\n",
      "0.99953762244\n",
      "0.995162020159\n",
      "0.999905418011\n",
      "0.999907008526\n"
     ]
    }
   ],
   "source": [
    "mldataF = sdata[(sdata['b'] == 'off') & (sdata['field'] >9) & (sdata['size'] > 12)]\n",
    "X = mldataF[['field','frequency','size','K', 'gyro']]\n",
    "Y1 = mldataF[['tan1']]\n",
    "Y2 = mldataF[['tau']]*1e9  #tau in nanoseconds\n",
    "Y3 = mldataF[['5:3']]\n",
    "Y4 = mldataF[['fifth']]\n",
    "Y5 = mldataF[['third']]\n",
    "\n",
    "X_train, X_test , Y1_train , Y1_test = train_test_split(X,Y1,test_size=0.15,random_state=26)\n",
    "model1 = RandomForestRegressor(n_estimators=100, max_features=5)\n",
    "model1.fit(X_train, Y1_train.values.ravel())\n",
    "\n",
    "X_train, X_test , Y2_train , Y2_test = train_test_split(X,Y2,test_size=0.15,random_state=26)\n",
    "model2 = RandomForestRegressor(n_estimators=100, max_features=5)\n",
    "model2.fit(X_train, Y2_train.values.ravel())\n",
    "\n",
    "X_train, X_test , Y3_train , Y3_test = train_test_split(X,Y3,test_size=0.15,random_state=26)\n",
    "model3 = RandomForestRegressor(n_estimators=100, max_features=5)\n",
    "model3.fit(X_train, Y3_train.values.ravel())\n",
    "\n",
    "X_train, X_test , Y4_train , Y4_test = train_test_split(X,Y4,test_size=0.15,random_state=26)\n",
    "model4 = RandomForestRegressor(n_estimators=100, max_features=5)\n",
    "model4.fit(X_train, Y4_train.values.ravel())\n",
    "\n",
    "X_train, X_test , Y5_train , Y6_test = train_test_split(X,Y5,test_size=0.15,random_state=26)\n",
    "model5 = RandomForestRegressor(n_estimators=100, max_features=5)\n",
    "model5.fit(X_train, Y5_train.values.ravel())\n",
    "\n",
    "print(model1.score(X_train,Y1_train))\n",
    "print(model2.score(X_train,Y2_train))\n",
    "print(model3.score(X_train,Y3_train))\n",
    "print(model4.score(X_train,Y4_train))\n",
    "print(model5.score(X_train,Y5_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output1 = open('mpsmodel-tan-frozen.pkl', 'wb')\n",
    "pickle.dump(model1, output1)\n",
    "output1.close()\n",
    "\n",
    "output2 = open('mpsmodel-tau-frozen.pkl', 'wb')\n",
    "pickle.dump(model2, output2)\n",
    "output2.close()\n",
    "\n",
    "output3 = open('mpsmodel-ratio-frozen.pkl', 'wb')\n",
    "pickle.dump(model3, output3)\n",
    "output3.close()\n",
    "\n",
    "output4 = open('mpsmodel-fifth-frozen.pkl', 'wb')\n",
    "pickle.dump(model4, output4)\n",
    "output4.close()\n",
    "\n",
    "output5 = open('mpsmodel-third-frozen.pkl', 'wb')\n",
    "pickle.dump(model5, output5)\n",
    "output5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brownian rotation on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998602140916\n",
      "0.999349246132\n",
      "0.990852441302\n",
      "0.998147928533\n",
      "0.998750912384\n"
     ]
    }
   ],
   "source": [
    "mldata = sdata[(sdata['b'] == 'on') & (sdata['field'] >9) & (sdata['size'] > 12)]\n",
    "X = mldata[['field','frequency','size','K', 'gyro','eta']]\n",
    "Y1 = mldata[['tan1']]\n",
    "Y2 = mldata[['tau']]*1e9  #tau in nanoseconds\n",
    "Y3 = mldata[['5:3']]\n",
    "Y4 = mldata[['fifth']]\n",
    "Y5 = mldata[['third']]\n",
    "\n",
    "X_train, X_test , Y1_train , Y1_test = train_test_split(X,Y1,test_size=0.15,random_state=26)\n",
    "model1b = RandomForestRegressor(n_estimators=100, max_features=6)\n",
    "model1b.fit(X_train, Y1_train.values.ravel())\n",
    "\n",
    "X_train, X_test , Y2_train , Y2_test = train_test_split(X,Y2,test_size=0.15,random_state=26)\n",
    "model2b = RandomForestRegressor(n_estimators=100, max_features=6)\n",
    "model2b.fit(X_train, Y2_train.values.ravel())\n",
    "\n",
    "X_train, X_test , Y3_train , Y3_test = train_test_split(X,Y3,test_size=0.15,random_state=26)\n",
    "model3b = RandomForestRegressor(n_estimators=100, max_features=6)\n",
    "model3b.fit(X_train, Y3_train.values.ravel())\n",
    "\n",
    "X_train, X_test , Y4_train , Y4_test = train_test_split(X,Y4,test_size=0.15,random_state=26)\n",
    "model4b = RandomForestRegressor(n_estimators=100, max_features=6)\n",
    "model4b.fit(X_train, Y4_train.values.ravel())\n",
    "\n",
    "X_train, X_test , Y5_train , Y6_test = train_test_split(X,Y5,test_size=0.15,random_state=26)\n",
    "model5b = RandomForestRegressor(n_estimators=100, max_features=6)\n",
    "model5b.fit(X_train, Y5_train.values.ravel())\n",
    "\n",
    "print(model1b.score(X_train,Y1_train))\n",
    "print(model2b.score(X_train,Y2_train))\n",
    "print(model3b.score(X_train,Y3_train))\n",
    "print(model4b.score(X_train,Y4_train))\n",
    "print(model5b.score(X_train,Y5_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output1b = open('mpsmodel-tan.pkl', 'wb')\n",
    "pickle.dump(model1b, output1b)\n",
    "output1b.close()\n",
    "\n",
    "output2b = open('mpsmodel-tau.pkl', 'wb')\n",
    "pickle.dump(model2b, output2b)\n",
    "output2b.close()\n",
    "\n",
    "output3b = open('mpsmodel-ratio.pkl', 'wb')\n",
    "pickle.dump(model3b, output3b)\n",
    "output3b.close()\n",
    "\n",
    "output4b = open('mpsmodel-fifth.pkl', 'wb')\n",
    "pickle.dump(model4b, output4b)\n",
    "output4b.close()\n",
    "\n",
    "output5b = open('mpsmodel-third.pkl', 'wb')\n",
    "pickle.dump(model5b, output5b)\n",
    "output5b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3]",
   "language": "python",
   "name": "conda-env-miniconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
